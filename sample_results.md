r=0

current #steps=0, #epochs=1
start training...
---------------
2024-01-04 09:16:28.432544
current #epochs=1, #steps=0
warm-up learning rate is 0.000000
start validation
mAP: 0.012666
AUC: 0.229798
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.045829
train_loss: 0.725927
valid_loss: 0.971177
validation finished
Epoch-1 lr: 0.0
epoch 1 training time: 21.363
---------------
2024-01-04 09:16:49.795895
current #epochs=2, #steps=50
warm-up learning rate is 0.000013
start validation
mAP: 0.015799
AUC: 0.227434
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.056875
train_loss: 0.487825
valid_loss: 0.851832
validation finished
Epoch-2 lr: 1.25e-05
epoch 2 training time: 20.744
---------------
2024-01-04 09:17:10.539462
current #epochs=3, #steps=100
warm-up learning rate is 0.000025
Epoch: [3][0/50]        Per Sample Total Time 0.23885   Per Sample Data Time 0.20206    Per Sample DNN Time 0.03678 Train Loss 0.3615
start validation
mAP: 0.016788
AUC: 0.239613
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.000622
train_loss: 0.266795
valid_loss: 0.779813
validation finished
Epoch-3 lr: 2.5e-05
epoch 3 training time: 20.985
---------------
2024-01-04 09:17:31.524571
current #epochs=4, #steps=150
warm-up learning rate is 0.000037
start validation
mAP: 0.017583
AUC: 0.243146
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.984600
train_loss: 0.135079
valid_loss: 0.734616
validation finished
Epoch-4 lr: 3.75e-05
epoch 4 training time: 20.978
---------------
2024-01-04 09:17:52.502354
current #epochs=5, #steps=200
warm-up learning rate is 0.000050
Epoch: [5][0/50]        Per Sample Total Time 0.27039   Per Sample Data Time 0.23775    Per Sample DNN Time 0.03264 Train Loss 0.0921
start validation
mAP: 0.018320
AUC: 0.247503
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.965017
train_loss: 0.072897
valid_loss: 0.714905
validation finished
Epoch-5 lr: 5e-05
epoch 5 training time: 21.017
---------------
2024-01-04 09:18:13.519022
current #epochs=6, #steps=250
warm-up learning rate is 0.000063
start validation
mAP: 0.018936
AUC: 0.252858
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.941193
train_loss: 0.047509
valid_loss: 0.706202
validation finished
Epoch-6 lr: 6.25e-05
epoch 6 training time: 21.037
---------------
2024-01-04 09:18:34.555935
current #epochs=7, #steps=300
warm-up learning rate is 0.000075
Epoch: [7][0/50]        Per Sample Total Time 0.25374   Per Sample Data Time 0.21990    Per Sample DNN Time 0.03384 Train Loss 0.0400
start validation
mAP: 0.018209
AUC: 0.255738
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.928491
train_loss: 0.036241
valid_loss: 0.702012
validation finished
Epoch-7 lr: 7.5e-05
epoch 7 training time: 19.500
---------------
2024-01-04 09:18:54.056322
current #epochs=8, #steps=350
warm-up learning rate is 0.000087
start validation
mAP: 0.018754
AUC: 0.260767
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.906487
train_loss: 0.031109
valid_loss: 0.699770
validation finished
Epoch-8 lr: 8.75e-05
epoch 8 training time: 19.523



For tokens = 8
Creating experiment directory: ./exp
Now starting training for 8 epochs
running on cuda
Total parameter number is : 87.977 million
Total trainable parameter number is : 87.977 million
now training with audioset, main metrics: mAP, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fd0740674f0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.500 every 5 epochs
current #steps=0, #epochs=1
start training...
---------------
2024-01-04 09:20:13.248169
current #epochs=1, #steps=0
warm-up learning rate is 0.000000
start validation
mAP: 0.015232
AUC: 0.227143
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.058242
train_loss: 0.732047
valid_loss: 0.974075
validation finished
Epoch-1 lr: 0.0
epoch 1 training time: 20.839
---------------
2024-01-04 09:20:34.088329
current #epochs=2, #steps=50
warm-up learning rate is 0.000013
start validation
mAP: 0.016400
AUC: 0.229805
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.045797
train_loss: 0.526180
valid_loss: 0.862170
validation finished
Epoch-2 lr: 1.25e-05
epoch 2 training time: 19.993
---------------
2024-01-04 09:20:54.081173
current #epochs=3, #steps=100
warm-up learning rate is 0.000025
Epoch: [3][0/50]        Per Sample Total Time 0.18315   Per Sample Data Time 0.15007    Per Sample DNN Time 0.03308   Train Loss 0.3886
start validation
mAP: 0.014406
AUC: 0.233498
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.028662
train_loss: 0.278264
valid_loss: 0.781455
validation finished
Epoch-3 lr: 2.5e-05
epoch 3 training time: 18.629
---------------
2024-01-04 09:21:12.710723
current #epochs=4, #steps=150
warm-up learning rate is 0.000037
start validation
mAP: 0.012681
AUC: 0.231319
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.038755
train_loss: 0.136586
valid_loss: 0.734806
validation finished
Epoch-4 lr: 3.75e-05
epoch 4 training time: 18.754
---------------
2024-01-04 09:21:31.464573
current #epochs=5, #steps=200
warm-up learning rate is 0.000050
Epoch: [5][0/50]        Per Sample Total Time 0.18151   Per Sample Data Time 0.13972    Per Sample DNN Time 0.04179   Train Loss 0.0967
start validation
mAP: 0.011986
AUC: 0.224179
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.072196
train_loss: 0.073094
valid_loss: 0.715001
validation finished
Epoch-5 lr: 5e-05
epoch 5 training time: 18.646
---------------
2024-01-04 09:21:50.110364
current #epochs=6, #steps=250
warm-up learning rate is 0.000063
start validation
mAP: 0.015213
AUC: 0.237311
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.011131
train_loss: 0.047463
valid_loss: 0.706342
validation finished
Epoch-6 lr: 6.25e-05
epoch 6 training time: 18.810
---------------
2024-01-04 09:22:08.920739
current #epochs=7, #steps=300
warm-up learning rate is 0.000075
Epoch: [7][0/50]        Per Sample Total Time 0.19591   Per Sample Data Time 0.16342    Per Sample DNN Time 0.03249   Train Loss 0.0417
start validation
mAP: 0.017383
AUC: 0.241144
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.993663
train_loss: 0.036407
valid_loss: 0.702211
validation finished
Epoch-7 lr: 7.5e-05
epoch 7 training time: 20.223
---------------
2024-01-04 09:22:29.144383
current #epochs=8, #steps=350
warm-up learning rate is 0.000087
start validation
mAP: 0.015155
AUC: 0.239945
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.999113
train_loss: 0.030906
valid_loss: 0.699978
validation finished
Epoch-8 lr: 8.75e-05
epoch 8 training time: 18.792

r=16
current #steps=0, #epochs=1
start training...
---------------
2024-01-04 09:26:49.439026
current #epochs=1, #steps=0
warm-up learning rate is 0.000000
start validation
mAP: 0.014819
AUC: 0.221155
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.086537
train_loss: 0.728161
valid_loss: 0.972998
validation finished
Epoch-1 lr: 0.0
epoch 1 training time: 21.247
---------------
2024-01-04 09:27:10.686343
current #epochs=2, #steps=50
warm-up learning rate is 0.000013
start validation
mAP: 0.016746
AUC: 0.234378
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.024606
train_loss: 0.523890
valid_loss: 0.862211
validation finished
Epoch-2 lr: 1.25e-05
epoch 2 training time: 21.196
---------------
2024-01-04 09:27:31.882568
current #epochs=3, #steps=100
warm-up learning rate is 0.000025
Epoch: [3][0/50]        Per Sample Total Time 0.26760   Per Sample Data Time 0.22348    Per Sample DNN Time 0.04412   Train Loss 0.3936
start validation
mAP: 0.015651
AUC: 0.247407
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.965445
train_loss: 0.279141
valid_loss: 0.782170
validation finished
Epoch-3 lr: 2.5e-05
epoch 3 training time: 19.246
---------------
2024-01-04 09:27:51.127988
current #epochs=4, #steps=150
warm-up learning rate is 0.000037
start validation
mAP: 0.016725
AUC: 0.240750
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.995454
train_loss: 0.137809
valid_loss: 0.735212
validation finished
Epoch-4 lr: 3.75e-05
epoch 4 training time: 19.235
---------------
2024-01-04 09:28:10.363430
current #epochs=5, #steps=200
warm-up learning rate is 0.000050
Epoch: [5][0/50]        Per Sample Total Time 0.25333   Per Sample Data Time 0.21215    Per Sample DNN Time 0.04118   Train Loss 0.0968
start validation
mAP: 0.017853
AUC: 0.232231
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.034523
train_loss: 0.073567
valid_loss: 0.715175
validation finished
Epoch-5 lr: 5e-05
epoch 5 training time: 20.605
---------------
2024-01-04 09:28:30.968708
current #epochs=6, #steps=250
warm-up learning rate is 0.000063
start validation
mAP: 0.016080
AUC: 0.238517
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.005620
train_loss: 0.047953
valid_loss: 0.706318
validation finished
Epoch-6 lr: 6.25e-05
epoch 6 training time: 19.292
---------------
2024-01-04 09:28:50.261247
current #epochs=7, #steps=300
warm-up learning rate is 0.000075
Epoch: [7][0/50]        Per Sample Total Time 0.26354   Per Sample Data Time 0.23262    Per Sample DNN Time 0.03092   Train Loss 0.0398
start validation
mAP: 0.017965
AUC: 0.253782
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.937108
train_loss: 0.037012
valid_loss: 0.702138
validation finished
Epoch-7 lr: 7.5e-05
epoch 7 training time: 20.811
---------------
2024-01-04 09:29:11.072147
current #epochs=8, #steps=350
warm-up learning rate is 0.000087
start validation
mAP: 0.015885
AUC: 0.242562
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.987242
train_loss: 0.031153
valid_loss: 0.699938
validation finished
Epoch-8 lr: 8.75e-05
epoch 8 training time: 19.441


r=32
current #steps=0, #epochs=1
start training...
---------------
2024-01-04 09:30:05.882541
current #epochs=1, #steps=0
warm-up learning rate is 0.000000
start validation
mAP: 0.023975
AUC: 0.242130
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.989195
train_loss: 0.735074
valid_loss: 0.975066
validation finished
Epoch-1 lr: 0.0
epoch 1 training time: 19.329
---------------
2024-01-04 09:30:25.212089
current #epochs=2, #steps=50
warm-up learning rate is 0.000013
start validation
mAP: 0.019908
AUC: 0.239988
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -0.998919
train_loss: 0.526703
valid_loss: 0.862192
validation finished
Epoch-2 lr: 1.25e-05
epoch 2 training time: 17.568
---------------
2024-01-04 09:30:42.780131
current #epochs=3, #steps=100
warm-up learning rate is 0.000025
Epoch: [3][0/50]        Per Sample Total Time 0.27962   Per Sample Data Time 0.25090    Per Sample DNN Time 0.02872   Train Loss 0.3889
start validation
mAP: 0.013412
AUC: 0.223485
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.075474
train_loss: 0.279174
valid_loss: 0.782137
validation finished
Epoch-3 lr: 2.5e-05
epoch 3 training time: 18.042
---------------
2024-01-04 09:31:00.822755
current #epochs=4, #steps=150
warm-up learning rate is 0.000037
start validation
mAP: 0.018912
AUC: 0.234910
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.022156
train_loss: 0.138576
valid_loss: 0.735611
validation finished
Epoch-4 lr: 3.75e-05
epoch 4 training time: 17.517
---------------
2024-01-04 09:31:18.339262
current #epochs=5, #steps=200
warm-up learning rate is 0.000050
Epoch: [5][0/50]        Per Sample Total Time 0.25626   Per Sample Data Time 0.22479    Per Sample DNN Time 0.03147   Train Loss 0.0974
start validation
mAP: 0.013301
AUC: 0.231175
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.039425
train_loss: 0.074155
valid_loss: 0.715578
validation finished
Epoch-5 lr: 5e-05
epoch 5 training time: 17.670
---------------
2024-01-04 09:31:36.009157
current #epochs=6, #steps=250
warm-up learning rate is 0.000063
start validation
mAP: 0.015298
AUC: 0.237266
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.011338
train_loss: 0.048669
valid_loss: 0.706661
validation finished
Epoch-6 lr: 6.25e-05
epoch 6 training time: 17.764
---------------
2024-01-04 09:31:53.772799
current #epochs=7, #steps=300
warm-up learning rate is 0.000075
Epoch: [7][0/50]        Per Sample Total Time 0.25902   Per Sample Data Time 0.21660    Per Sample DNN Time 0.04242   Train Loss 0.0397
start validation
mAP: 0.014995
AUC: 0.230578
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.042195
train_loss: 0.037184
valid_loss: 0.702347
validation finished
Epoch-7 lr: 7.5e-05
epoch 7 training time: 17.745
---------------
2024-01-04 09:32:11.518293
current #epochs=8, #steps=350
warm-up learning rate is 0.000087
start validation
mAP: 0.017455
AUC: 0.224844
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.069053
train_loss: 0.031552
valid_loss: 0.700105
validation finished
Epoch-8 lr: 8.75e-05
epoch 8 training time: 17.775


r=64:
---------------the train dataloader---------------
now using following mask: 48 freq, 192 time
now using mix-up with rate 0.500000
now process audioset
use dataset mean -4.268 and std 4.569 to normalize the input.
number of classes is 527
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process audioset
use dataset mean -4.268 and std 4.569 to normalize the input.
number of classes is 527
---------------AST Model Summary---------------
ImageNet pretraining: True, AudioSet pretraining: False
frequncey stride=12, time stride=10
number of patches=1010

Creating experiment directory: ./exp
Now starting training for 8 epochs
running on cuda
Total parameter number is : 87.977 million
Total trainable parameter number is : 87.977 million
now training with audioset, main metrics: mAP, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7ffaac13e4f0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.500 every 5 epochs
current #steps=0, #epochs=1
start training...
---------------
2024-01-04 09:33:14.849692
current #epochs=1, #steps=0
warm-up learning rate is 0.000000
start validation
mAP: 0.016685
AUC: 0.229071
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.049219
train_loss: 0.723112
valid_loss: 0.970633
validation finished
Epoch-1 lr: 0.0
epoch 1 training time: 16.821
---------------
2024-01-04 09:33:31.671027
current #epochs=2, #steps=50
warm-up learning rate is 0.000013
start validation
mAP: 0.016071
AUC: 0.238743
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.004588
train_loss: 0.518010
valid_loss: 0.860848
validation finished
Epoch-2 lr: 1.25e-05
epoch 2 training time: 15.124
---------------
2024-01-04 09:33:46.795696
current #epochs=3, #steps=100
warm-up learning rate is 0.000025
Epoch: [3][0/50]        Per Sample Total Time 0.24717   Per Sample Data Time 0.21549    Per Sample DNN Time 0.03168   Train Loss 0.3874
start validation
mAP: 0.018299
AUC: 0.238057
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.007720
train_loss: 0.275966
valid_loss: 0.780447
validation finished
Epoch-3 lr: 2.5e-05
epoch 3 training time: 16.547
---------------
2024-01-04 09:34:03.342105
current #epochs=4, #steps=150
warm-up learning rate is 0.000037
start validation
mAP: 0.014040
AUC: 0.224165
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.072261
train_loss: 0.135732
valid_loss: 0.734568
validation finished
Epoch-4 lr: 3.75e-05
epoch 4 training time: 15.159
---------------
2024-01-04 09:34:18.501020
current #epochs=5, #steps=200
warm-up learning rate is 0.000050
Epoch: [5][0/50]        Per Sample Total Time 0.23594   Per Sample Data Time 0.20080    Per Sample DNN Time 0.03514   Train Loss 0.0941
start validation
mAP: 0.014383
AUC: 0.224781
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.069351
train_loss: 0.072611
valid_loss: 0.714984
validation finished
Epoch-5 lr: 5e-05
epoch 5 training time: 15.151
---------------
2024-01-04 09:34:33.651697
current #epochs=6, #steps=250
warm-up learning rate is 0.000063
start validation
mAP: 0.019622
AUC: 0.236790
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.013518
train_loss: 0.048025
valid_loss: 0.706352
validation finished
Epoch-6 lr: 6.25e-05
epoch 6 training time: 16.583
---------------
2024-01-04 09:34:50.234570
current #epochs=7, #steps=300
warm-up learning rate is 0.000075
Epoch: [7][0/50]        Per Sample Total Time 0.25365   Per Sample Data Time 0.22639    Per Sample DNN Time 0.02727   Train Loss 0.0454
start validation
mAP: 0.018581
AUC: 0.230353
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.043246
train_loss: 0.036920
valid_loss: 0.702200
validation finished
Epoch-7 lr: 7.5e-05
epoch 7 training time: 15.208
---------------
2024-01-04 09:35:05.442533
current #epochs=8, #steps=350
warm-up learning rate is 0.000087
start validation
mAP: 0.014717
AUC: 0.224131
Avg Precision: 0.004587
Avg Recall: 1.000000
d_prime: -1.072422
train_loss: 0.030942
valid_loss: 0.700006
validation finished
Epoch-8 lr: 8.75e-05
epoch 8 training time: 15.102